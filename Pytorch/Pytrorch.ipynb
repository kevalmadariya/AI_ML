{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlzGuCy5UH_T",
        "outputId": "81a136a1-74cc-4257-cf02-138b5610b80b",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9emfG6uf2SU",
        "outputId": "cd9ca071-b726-4810-fb49-550dde196778"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.0)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/400.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import optuna\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "GA9sJsGhUTDM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "6CK6OqfxjRFR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd\n"
      ],
      "metadata": {
        "id": "FUkB8f-rRKwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(3.0, requires_grad=True)"
      ],
      "metadata": {
        "id": "RRH-1BzzRRiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7WebwT6UDBU",
        "outputId": "60edc63b-6968-4d60-e650-5ae9c9c98821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3., requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x**2"
      ],
      "metadata": {
        "id": "DCBo9Xm5UZmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()"
      ],
      "metadata": {
        "id": "F6s3Y9gKUvAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BShe0qiJUxqu",
        "outputId": "0fa57a6a-00de-49a0-a232-d22badcabfc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic NN pipeline using Autograd"
      ],
      "metadata": {
        "id": "ZyohUw00VJJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "GNz_1KbLeljg",
        "outputId": "a19b6a0e-7b5b-4053-e323-6837c1bc12a0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0  ...          17.33           184.60      2019.0            0.1622   \n",
              "1  ...          23.41           158.80      1956.0            0.1238   \n",
              "2  ...          25.53           152.50      1709.0            0.1444   \n",
              "3  ...          26.50            98.87       567.7            0.2098   \n",
              "4  ...          16.67           152.20      1575.0            0.1374   \n",
              "\n",
              "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0             0.6656           0.7119                0.2654          0.4601   \n",
              "1             0.1866           0.2416                0.1860          0.2750   \n",
              "2             0.4245           0.4504                0.2430          0.3613   \n",
              "3             0.8663           0.6869                0.2575          0.6638   \n",
              "4             0.2050           0.4000                0.1625          0.2364   \n",
              "\n",
              "   fractal_dimension_worst  Unnamed: 32  \n",
              "0                  0.11890          NaN  \n",
              "1                  0.08902          NaN  \n",
              "2                  0.08758          NaN  \n",
              "3                  0.17300          NaN  \n",
              "4                  0.07678          NaN  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71e985f8-8dee-493f-9622-0e33437c0127\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71e985f8-8dee-493f-9622-0e33437c0127')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71e985f8-8dee-493f-9622-0e33437c0127 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71e985f8-8dee-493f-9622-0e33437c0127');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-411b5c03-65aa-419c-917e-2d96e671653c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-411b5c03-65aa-419c-917e-2d96e671653c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-411b5c03-65aa-419c-917e-2d96e671653c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['id','Unnamed: 32'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "6QvCFpztDqtm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.iloc[:, 0], test_size=0.2)"
      ],
      "metadata": {
        "id": "rOVYbf-3mCu1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scalar = StandardScaler()\n",
        "X_train = scalar.fit_transform(X_train)\n",
        "X_test = scalar.transform(X_test)"
      ],
      "metadata": {
        "id": "RCQehdgvnIu3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.transform(y_test)"
      ],
      "metadata": {
        "id": "JlreAVUJnthC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.from_numpy(X_train).float()\n",
        "X_test_tensor = torch.from_numpy(X_test).float()\n",
        "y_train_tensor = torch.from_numpy(y_train)\n",
        "y_test_tensor = torch.from_numpy(y_test)"
      ],
      "metadata": {
        "id": "AYuWuEzmoJa5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MySimpleNN():\n",
        "\n",
        "  def __init__(self, X):\n",
        "\n",
        "    self.weights = torch.rand(X.shape[1], 1, dtype=torch.float64, requires_grad=True)\n",
        "    self.bias = torch.zeros(1, dtype=torch.float64, requires_grad=True)\n",
        "\n",
        "  def forward(self, X):\n",
        "    z = torch.matmul(X, self.weights) + self.bias\n",
        "    y_pred = torch.sigmoid(z)\n",
        "    return y_pred\n",
        "\n",
        "  def loss_function(self, y_pred, y):\n",
        "    # Clamp predictions to avoid log(0)\n",
        "    epsilon = 1e-7\n",
        "    y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = -(y_train_tensor * torch.log(y_pred) + (1 - y_train_tensor) * torch.log(1 - y_pred)).mean()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "Ciw6Ih8Anxio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 25\n",
        "learning_rate = 0.1"
      ],
      "metadata": {
        "id": "3HIMP4O8r4nL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MySimpleNN(X_train_tensor)"
      ],
      "metadata": {
        "id": "v5vapfh6trVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "  y_pred = model.forward(X_train_tensor)\n",
        "\n",
        "  loss = model.loss_function( y_pred , y_train_tensor)\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  #now for updation no need of add this into DCG(dynamic computation graph)\n",
        "  with torch.no_grad():\n",
        "    model.weights -= learning_rate * model.weights.grad\n",
        "    model.bias -= learning_rate * model.bias.grad\n",
        "\n",
        "  model.weights.grad.zero_()\n",
        "  model.bias.grad.zero_()\n",
        "\n",
        "  print(f'epoch : {epoch+1} , loss : {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-KQWxp4r-2e",
        "outputId": "e8323ec4-be7f-4d23-dbe6-d10ec35c6faf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 1 , loss : 3.641935817326634\n",
            "epoch : 2 , loss : 3.525171469333716\n",
            "epoch : 3 , loss : 3.404200825864371\n",
            "epoch : 4 , loss : 3.280857935939187\n",
            "epoch : 5 , loss : 3.1546629116426708\n",
            "epoch : 6 , loss : 3.025235212154597\n",
            "epoch : 7 , loss : 2.889736975189271\n",
            "epoch : 8 , loss : 2.7484364613954333\n",
            "epoch : 9 , loss : 2.6036534840833876\n",
            "epoch : 10 , loss : 2.4491347588218253\n",
            "epoch : 11 , loss : 2.2932683224029624\n",
            "epoch : 12 , loss : 2.142873683571512\n",
            "epoch : 13 , loss : 1.996843514205838\n",
            "epoch : 14 , loss : 1.8589282945428487\n",
            "epoch : 15 , loss : 1.7282655902460886\n",
            "epoch : 16 , loss : 1.6018960842037244\n",
            "epoch : 17 , loss : 1.4846494754446968\n",
            "epoch : 18 , loss : 1.3802637977801713\n",
            "epoch : 19 , loss : 1.2890619574357296\n",
            "epoch : 20 , loss : 1.2108911560624744\n",
            "epoch : 21 , loss : 1.14471835854993\n",
            "epoch : 22 , loss : 1.0872938960079728\n",
            "epoch : 23 , loss : 1.0396600755675085\n",
            "epoch : 24 , loss : 0.9997022656485353\n",
            "epoch : 25 , loss : 0.9674538458712352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_pred = model.forward(X_test_tensor)\n",
        "  y_pred_class = (y_pred > 0.9).float()\n",
        "  acc = (y_pred_class == y_test_tensor).float().mean()\n",
        "  print(f'accuracy: {acc.item()*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5meHHqNEFOj",
        "outputId": "12300495-0634-47a6-e774-89dd1aa793a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 58.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NN Module\n"
      ],
      "metadata": {
        "id": "YzdUZx8dE3NO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#till the 9th cell all remain as it is of above section"
      ],
      "metadata": {
        "id": "V2Fj-_YVE7UK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MySimpleNN(torch.nn.Module):\n",
        "\n",
        "  def __init__(self,X):\n",
        "    super().__init__()\n",
        "    self.linear = torch.nn.Linear(X.shape[1], 1, dtype=torch.float32)\n",
        "    self.sigmoid = torch.nn.Sigmoid().float()\n",
        "\n",
        "  def forward(self, X):\n",
        "    z = self.linear(X)\n",
        "    y_pred = self.sigmoid(z)\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "oV3e8nwXFwu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MySimpleNN(X_train_tensor)"
      ],
      "metadata": {
        "id": "mT9ktCQlGcXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 25\n",
        "learning_rate = 0.1"
      ],
      "metadata": {
        "id": "Hzu-MoWeGeSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "QHYBg1y3GnJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  y_pred = model(X_train_tensor)\n",
        "\n",
        "  loss = loss_function(y_pred.float(), y_train_tensor.view(-1, 1).float())\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  print(f'Epochs: {epoch + 1},Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "collapsed": true,
        "id": "C-0NJAK_GhdQ",
        "outputId": "aab6133a-21ed-455c-c61d-b90f82d7309b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-296315209.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1719297940.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Double and Float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model evaluation\n",
        "with torch.no_grad():\n",
        "  y_pred = model.forward(X_test_tensor)\n",
        "  y_pred = (y_pred > 0.5).float()\n",
        "  accuracy = (y_pred == y_test_tensor).float().mean()\n",
        "  print(f'Accuracy: {accuracy.item()}')\n"
      ],
      "metadata": {
        "id": "wozGNPcKHPiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and DataLoader"
      ],
      "metadata": {
        "id": "26muGL4VLBgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self,features,labels):\n",
        "    self.features = features\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.features[idx], self.labels[idx]\n"
      ],
      "metadata": {
        "id": "AchdAXPALG2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = CustomDataset(X_test_tensor, y_test_tensor)"
      ],
      "metadata": {
        "id": "QaJyr08cL8n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
        "test_loader = DataLoader(test_dataset,batch_size=32,shuffle=False)"
      ],
      "metadata": {
        "id": "6IJOWZ-CLorB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MySimpleNN(torch.nn.Module):\n",
        "\n",
        "  def __init__(self,X):\n",
        "    super().__init__()\n",
        "    self.linear = torch.nn.Linear(X.shape[1], 1, dtype=torch.float32)\n",
        "    self.sigmoid = torch.nn.Sigmoid().float()\n",
        "\n",
        "  def forward(self, X):\n",
        "    z = self.linear(X)\n",
        "    y_pred = self.sigmoid(z)\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "kSMzMV7LMCw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "    y_pred = model(batch_features)\n",
        "\n",
        "    loss = loss_function(y_pred.float(), y_train_tensor.view(-1, 1).float())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f'Epochs: {epoch + 1},Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "49d65b38-4c41-400b-d062-78bf7cd8c0dc",
        "id": "pv8O8zXsMy6F"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-767159397.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3007881930.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Double and Float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MySimpleNN(X_train_tensor)"
      ],
      "metadata": {
        "id": "JpDsxdq8MN55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 25\n",
        "learning_rate = 0.1"
      ],
      "metadata": {
        "id": "LkOpuCQkMQTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "KDA3AKkIMSLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "    y_pred = model(batch_features)\n",
        "\n",
        "    loss = loss_function(y_pred.float(), y_train_tensor.view(-1, 1).float())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f'Epochs: {epoch + 1},Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "KDK-xqk5MUM7",
        "outputId": "5db9718e-435f-40d5-b602-8dcc0cb3d8ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-767159397.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1719297940.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Double and Float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation using test_loader\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "accuracy_list = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_features, batch_labels in test_loader:\n",
        "        # Forward pass\n",
        "        y_pred = model(batch_features)\n",
        "        y_pred = (y_pred > 0.8).float()  # Convert probabilities to binary predictions\n",
        "\n",
        "        # Calculate accuracy for the current batch\n",
        "        batch_accuracy = (y_pred.view(-1) == batch_labels).float().mean().item()\n",
        "        accuracy_list.append(batch_accuracy)\n",
        "\n",
        "# Calculate overall accuracy\n",
        "overall_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
        "print(f'Accuracy: {overall_accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "1c7M9sbxM6tL",
        "outputId": "3f5e52db-04e0-497a-8c9e-1e03d850624e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3515623785.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert probabilities to binary predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1719297940.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Double and Float"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FashionMNIST using Dataset and Dataloader"
      ],
      "metadata": {
        "id": "_hxUH1ZmNW_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies as needed:\n",
        "# pip install kagglehub[pandas-datasets]\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# Set the path to the file you'd like to load\n",
        "file_path = \"fashion-mnist_train.csv\"\n",
        "\n",
        "# Load the latest version\n",
        "df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"zalando-research/fashionmnist\",\n",
        "  file_path,\n",
        "  # Provide any additional arguments like\n",
        "  # sql_query or pandas_kwargs. See the\n",
        "  # documenation for more information:\n",
        "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
        ")\n",
        "\n",
        "print(\"First 5 records:\", df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4kGEGH2TYBU",
        "outputId": "9aab25cd-eea1-4a81-b99e-a30f8a22f09b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-251015765.py:10: DeprecationWarning: Use dataset_load() instead of load_dataset(). load_dataset() will be removed in a future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'fashionmnist' dataset.\n",
            "First 5 records:    label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
            "0      2       0       0       0       0       0       0       0       0   \n",
            "1      9       0       0       0       0       0       0       0       0   \n",
            "2      6       0       0       0       0       0       0       0       5   \n",
            "3      0       0       0       0       1       2       0       0       0   \n",
            "4      3       0       0       0       0       0       0       0       0   \n",
            "\n",
            "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
            "0       0  ...         0         0         0         0         0         0   \n",
            "1       0  ...         0         0         0         0         0         0   \n",
            "2       0  ...         0         0         0        30        43         0   \n",
            "3       0  ...         3         0         0         0         0         1   \n",
            "4       0  ...         0         0         0         0         0         0   \n",
            "\n",
            "   pixel781  pixel782  pixel783  pixel784  \n",
            "0         0         0         0         0  \n",
            "1         0         0         0         0  \n",
            "2         0         0         0         0  \n",
            "3         0         0         0         0  \n",
            "4         0         0         0         0  \n",
            "\n",
            "[5 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bbc23fc",
        "outputId": "9c6f1e0e-3cb6-4d9b-e619-35912898d016"
      },
      "source": [
        "df = df.head(6000)\n",
        "print(\"First 5 records of the new df:\", df.head())\n",
        "print(\"Number of rows in the new df:\", len(df))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 records of the new df:    label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
            "0      2       0       0       0       0       0       0       0       0   \n",
            "1      9       0       0       0       0       0       0       0       0   \n",
            "2      6       0       0       0       0       0       0       0       5   \n",
            "3      0       0       0       0       1       2       0       0       0   \n",
            "4      3       0       0       0       0       0       0       0       0   \n",
            "\n",
            "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
            "0       0  ...         0         0         0         0         0         0   \n",
            "1       0  ...         0         0         0         0         0         0   \n",
            "2       0  ...         0         0         0        30        43         0   \n",
            "3       0  ...         3         0         0         0         0         1   \n",
            "4       0  ...         0         0         0         0         0         0   \n",
            "\n",
            "   pixel781  pixel782  pixel783  pixel784  \n",
            "0         0         0         0         0  \n",
            "1         0         0         0         0  \n",
            "2         0         0         0         0  \n",
            "3         0         0         0         0  \n",
            "4         0         0         0         0  \n",
            "\n",
            "[5 rows x 785 columns]\n",
            "Number of rows in the new df: 6000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df.iloc[:, 1:].values\n",
        "y_train = df.iloc[:, 0].values"
      ],
      "metadata": {
        "id": "5lNcHW_lUdsd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)"
      ],
      "metadata": {
        "id": "sk0oUAQQU1SH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train/255.0\n",
        "X_test = X_test/255.0"
      ],
      "metadata": {
        "id": "ZI-FPWI8UnkX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = torch.tensor(features, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n"
      ],
      "metadata": {
        "id": "g9kpfaQnUyH9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for  CNN\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = torch.tensor(features, dtype=torch.float32).reshape(-1,1, 28, 28)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n"
      ],
      "metadata": {
        "id": "3aPMiBW1UJkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(X_train, y_train)\n",
        "test_dataset = CustomDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "DusCQzWDVB1a"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
        "test_loader = DataLoader(test_dataset,batch_size=32,shuffle=False)"
      ],
      "metadata": {
        "id": "d98onT-SVF4M"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class MyNN(nn.Module):\n",
        "    def __init__(self, num_features):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(num_features, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.3),\n",
        "            nn.Linear(64, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "B0YOwxowVKkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set learning rate and epochs\n",
        "epochs = 100\n",
        "learning_rate = 0.1"
      ],
      "metadata": {
        "id": "47fgr9UnVTBS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instatiate the model\n",
        "model = MyNN(X_train.shape[1])\n",
        "\n",
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr= learning_rate)"
      ],
      "metadata": {
        "id": "Dx7Yt5xRVVeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  total_epoch_loss = 0\n",
        "\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(batch_features)\n",
        "\n",
        "    # calculate loss\n",
        "    loss = criterion(outputs, batch_labels)\n",
        "\n",
        "    # back pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # update grads\n",
        "    optimizer.step()\n",
        "\n",
        "    total_epoch_loss = total_epoch_loss + loss.item()\n",
        "\n",
        "  avg_loss = total_epoch_loss/len(train_loader)\n",
        "  print(f'Epoch: {epoch + 1} , Loss: {avg_loss}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Bw52uadVVYOe",
        "outputId": "5a38232c-4e45-43f5-adb4-f0dc052c2f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3671931611.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-993312961.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Double and Float"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optina FashionMNIST"
      ],
      "metadata": {
        "id": "xK4Esp_kX_Hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cell 104 to 114 as it"
      ],
      "metadata": {
        "id": "o8wj0iFsYHhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNN(torch.nn.Module):\n",
        "\n",
        "  def __init__(self,input_dim,output_dim,num_hidden_layer,neurons_per_layer,dropout):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    for i in range(num_hidden_layer):\n",
        "        layers.append(nn.Linear(input_dim, neurons_per_layer))\n",
        "        layers.append(nn.BatchNorm1d(neurons_per_layer))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Dropout(p=dropout))\n",
        "        input_dim = neurons_per_layer\n",
        "\n",
        "    layers.append(nn.Linear(neurons_per_layer, output_dim))\n",
        "\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.model(X)\n"
      ],
      "metadata": {
        "id": "kPt0CrR7YPic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "  num_hidden_layer = trial.suggest_int('num_hidden_layer', 1, 5)\n",
        "  neurons_per_layer = trial.suggest_int('neurons_per_layer', 8, 128, step=8)\n",
        "  dropout = trial.suggest_float('dropout', 0.1, 0.5, step=0.1)\n",
        "\n",
        "  train_loader = DataLoader(train_dataset , batch_size=32 , shuffle=True)\n",
        "  test_loader = DataLoader(test_dataset , batch_size=32 , shuffle=False)\n",
        "\n",
        "  input_dim = 784\n",
        "  output_dim = 10\n",
        "\n",
        "  model = MyNN(input_dim,output_dim,num_hidden_layer,neurons_per_layer,dropout)\n",
        "\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    for batch_features, batch_labels in train_loader:\n",
        "\n",
        "      y_pred = model(batch_features)\n",
        "\n",
        "      loss = loss_function(y_pred, batch_labels)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for batch_features, batch_labels in test_loader:\n",
        "\n",
        "      y_pred = model(batch_features)\n",
        "\n",
        "      _, predicted = torch.max(y_pred.data, 1)\n",
        "\n",
        "      total += batch_labels.size(0)\n",
        "      correct += (predicted == batch_labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "Wg3Nz-0UZOeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZUu59WUeoZq",
        "outputId": "4dbc8a7e-a9bc-4c2c-cc17-5c301e667179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-18 04:16:10,559] A new study created in memory with name: no-name-6751bd44-18ca-40c8-8356-3da19dfb3515\n",
            "[I 2025-10-18 04:16:42,217] Trial 0 finished with value: 100.0 and parameters: {'num_hidden_layer': 4, 'neurons_per_layer': 64, 'dropout': 0.30000000000000004}. Best is trial 0 with value: 100.0.\n",
            "[I 2025-10-18 04:17:01,083] Trial 1 finished with value: 100.0 and parameters: {'num_hidden_layer': 1, 'neurons_per_layer': 88, 'dropout': 0.1}. Best is trial 0 with value: 100.0.\n",
            "[I 2025-10-18 04:17:26,728] Trial 2 finished with value: 100.0 and parameters: {'num_hidden_layer': 2, 'neurons_per_layer': 112, 'dropout': 0.2}. Best is trial 0 with value: 100.0.\n",
            "[I 2025-10-18 04:17:54,927] Trial 3 finished with value: 100.0 and parameters: {'num_hidden_layer': 3, 'neurons_per_layer': 72, 'dropout': 0.1}. Best is trial 0 with value: 100.0.\n",
            "[I 2025-10-18 04:18:16,408] Trial 4 finished with value: 100.0 and parameters: {'num_hidden_layer': 1, 'neurons_per_layer': 112, 'dropout': 0.2}. Best is trial 0 with value: 100.0.\n",
            "[I 2025-10-18 04:18:45,985] Trial 5 finished with value: 100.0 and parameters: {'num_hidden_layer': 5, 'neurons_per_layer': 16, 'dropout': 0.2}. Best is trial 0 with value: 100.0.\n",
            "[I 2025-10-18 04:19:27,829] Trial 6 finished with value: 100.0 and parameters: {'num_hidden_layer': 5, 'neurons_per_layer': 112, 'dropout': 0.1}. Best is trial 0 with value: 100.0.\n",
            "[I 2025-10-18 04:20:00,134] Trial 7 finished with value: 100.0 and parameters: {'num_hidden_layer': 4, 'neurons_per_layer': 80, 'dropout': 0.1}. Best is trial 0 with value: 100.0.\n",
            "[I 2025-10-18 04:20:32,949] Trial 8 finished with value: 100.0 and parameters: {'num_hidden_layer': 5, 'neurons_per_layer': 40, 'dropout': 0.2}. Best is trial 0 with value: 100.0.\n",
            "[I 2025-10-18 04:21:04,610] Trial 9 finished with value: 100.0 and parameters: {'num_hidden_layer': 4, 'neurons_per_layer': 64, 'dropout': 0.4}. Best is trial 0 with value: 100.0.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_value"
      ],
      "metadata": {
        "id": "_A-3p7p4jMvf",
        "outputId": "99503ebf-0c78-4727-bd57-d3facc04347c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100.0"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN FashionMNIST\n"
      ],
      "metadata": {
        "id": "cRtmQs5FOm8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# do required step from above sells"
      ],
      "metadata": {
        "id": "Ps7WjIb_Q5ES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class MYCNN(nn.Module):\n",
        "    def __init__(self, input_feature):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(input_feature, 32, kernel_size=3 , padding = 'same'),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3 , padding = 'same'),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64*7*7 , 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.3),\n",
        "\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.3),\n",
        "\n",
        "            nn.Linear(64, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "CvgOvWUoOsMs"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run some sells required."
      ],
      "metadata": {
        "id": "UoiSX51ESXzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instatiate the model\n",
        "model = MYCNN(X_train.shape[1])\n",
        "\n",
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr= learning_rate)"
      ],
      "metadata": {
        "id": "2djVWhjMSikb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instatiate the model for CNNNNNNNNNN\n",
        "model = MYCNN(1)\n",
        "\n",
        "# loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr= learning_rate)"
      ],
      "metadata": {
        "id": "c35F30xbUdie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  total_epoch_loss = 0\n",
        "\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(batch_features)\n",
        "\n",
        "    # calculate loss\n",
        "    loss = criterion(outputs, batch_labels)\n",
        "\n",
        "    # back pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # update grads\n",
        "    optimizer.step()\n",
        "\n",
        "    total_epoch_loss = total_epoch_loss + loss.item()\n",
        "\n",
        "  avg_loss = total_epoch_loss/len(train_loader)\n",
        "  print(f'Epoch: {epoch + 1} , Loss: {avg_loss}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLuJGD2STLny",
        "outputId": "2e64c81d-c337-4e43-dbc7-09c61b00a2f8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 , Loss: 0.9481124866008759\n",
            "Epoch: 2 , Loss: 0.5937423568964004\n",
            "Epoch: 3 , Loss: 0.4922902261217435\n",
            "Epoch: 4 , Loss: 0.4249120886127154\n",
            "Epoch: 5 , Loss: 0.374395148580273\n",
            "Epoch: 6 , Loss: 0.3493433831632137\n",
            "Epoch: 7 , Loss: 0.32863549614946047\n",
            "Epoch: 8 , Loss: 0.2906387224793434\n",
            "Epoch: 9 , Loss: 0.27091990056137244\n",
            "Epoch: 10 , Loss: 0.24554967017223436\n",
            "Epoch: 11 , Loss: 0.21695492319762708\n",
            "Epoch: 12 , Loss: 0.2168485192830364\n",
            "Epoch: 13 , Loss: 0.20550900849203269\n",
            "Epoch: 14 , Loss: 0.18712161439160505\n",
            "Epoch: 15 , Loss: 0.18934133579333623\n",
            "Epoch: 16 , Loss: 0.1603594495045642\n",
            "Epoch: 17 , Loss: 0.15338418347140154\n",
            "Epoch: 18 , Loss: 0.15199346935997407\n",
            "Epoch: 19 , Loss: 0.14347378966398538\n",
            "Epoch: 20 , Loss: 0.12092750752344728\n",
            "Epoch: 21 , Loss: 0.10780199913308025\n",
            "Epoch: 22 , Loss: 0.09898362302454189\n",
            "Epoch: 23 , Loss: 0.11165239964146167\n",
            "Epoch: 24 , Loss: 0.10382100226047139\n",
            "Epoch: 25 , Loss: 0.0846105806529522\n",
            "Epoch: 26 , Loss: 0.08034321104486783\n",
            "Epoch: 27 , Loss: 0.06256722987396643\n",
            "Epoch: 28 , Loss: 0.08292064127745107\n",
            "Epoch: 29 , Loss: 0.06255220097586668\n",
            "Epoch: 30 , Loss: 0.07374322147322042\n",
            "Epoch: 31 , Loss: 0.05665181635102878\n",
            "Epoch: 32 , Loss: 0.06641893431757732\n",
            "Epoch: 33 , Loss: 0.07953889548177055\n",
            "Epoch: 34 , Loss: 0.06986210388616504\n",
            "Epoch: 35 , Loss: 0.059732739046836895\n",
            "Epoch: 36 , Loss: 0.05308918934451261\n",
            "Epoch: 37 , Loss: 0.04340625201177318\n",
            "Epoch: 38 , Loss: 0.055476885117871765\n",
            "Epoch: 39 , Loss: 0.034983316191646734\n",
            "Epoch: 40 , Loss: 0.0562864493005327\n",
            "Epoch: 41 , Loss: 0.03765616188347243\n",
            "Epoch: 42 , Loss: 0.035235115877051915\n",
            "Epoch: 43 , Loss: 0.05036925211272319\n",
            "Epoch: 44 , Loss: 0.04198657431235309\n",
            "Epoch: 45 , Loss: 0.05074487867622035\n",
            "Epoch: 46 , Loss: 0.02981833912606817\n",
            "Epoch: 47 , Loss: 0.05546631002087148\n",
            "Epoch: 48 , Loss: 0.04242368126055226\n",
            "Epoch: 49 , Loss: 0.049523168216110205\n",
            "Epoch: 50 , Loss: 0.031112360159216527\n",
            "Epoch: 51 , Loss: 0.024281182310248065\n",
            "Epoch: 52 , Loss: 0.028349695467480462\n",
            "Epoch: 53 , Loss: 0.014975495553932584\n",
            "Epoch: 54 , Loss: 0.017761270104886838\n",
            "Epoch: 55 , Loss: 0.02884567195859745\n",
            "Epoch: 56 , Loss: 0.020028101777406847\n",
            "Epoch: 57 , Loss: 0.021879943398283405\n",
            "Epoch: 58 , Loss: 0.038609281201861446\n",
            "Epoch: 59 , Loss: 0.01778859701900122\n",
            "Epoch: 60 , Loss: 0.0305530515134645\n",
            "Epoch: 61 , Loss: 0.03218816494713489\n",
            "Epoch: 62 , Loss: 0.028484102026801943\n",
            "Epoch: 63 , Loss: 0.018130262667461164\n",
            "Epoch: 64 , Loss: 0.015491956960795505\n",
            "Epoch: 65 , Loss: 0.013478561729687043\n",
            "Epoch: 66 , Loss: 0.025354129070801718\n",
            "Epoch: 67 , Loss: 0.016694797970873577\n",
            "Epoch: 68 , Loss: 0.014330522738497772\n",
            "Epoch: 69 , Loss: 0.006746810437622723\n",
            "Epoch: 70 , Loss: 0.012482007626095993\n",
            "Epoch: 71 , Loss: 0.02347855742252856\n",
            "Epoch: 72 , Loss: 0.018190549630154464\n",
            "Epoch: 73 , Loss: 0.009674189383708457\n",
            "Epoch: 74 , Loss: 0.01311421895248903\n",
            "Epoch: 75 , Loss: 0.01931358810404163\n",
            "Epoch: 76 , Loss: 0.020164999031908337\n",
            "Epoch: 77 , Loss: 0.012371606757025498\n",
            "Epoch: 78 , Loss: 0.022803296517070824\n",
            "Epoch: 79 , Loss: 0.008964026637467365\n",
            "Epoch: 80 , Loss: 0.00948404463354033\n",
            "Epoch: 81 , Loss: 0.025188249740880717\n",
            "Epoch: 82 , Loss: 0.015493689435318932\n",
            "Epoch: 83 , Loss: 0.02407809285997549\n",
            "Epoch: 84 , Loss: 0.016512721683375274\n",
            "Epoch: 85 , Loss: 0.009656432747915838\n",
            "Epoch: 86 , Loss: 0.007641648843486451\n",
            "Epoch: 87 , Loss: 0.010494186414370384\n",
            "Epoch: 88 , Loss: 0.01900526033496514\n",
            "Epoch: 89 , Loss: 0.016492118354046095\n",
            "Epoch: 90 , Loss: 0.02184931834403566\n",
            "Epoch: 91 , Loss: 0.011965255638391833\n",
            "Epoch: 92 , Loss: 0.011780181182723861\n",
            "Epoch: 93 , Loss: 0.016588533685957526\n",
            "Epoch: 94 , Loss: 0.007682033506512009\n",
            "Epoch: 95 , Loss: 0.007885015259376094\n",
            "Epoch: 96 , Loss: 0.014085743009850755\n",
            "Epoch: 97 , Loss: 0.01985808140481898\n",
            "Epoch: 98 , Loss: 0.01927899845086358\n",
            "Epoch: 99 , Loss: 0.02010972104978464\n",
            "Epoch: 100 , Loss: 0.013999032355028475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9KNgkTbV577",
        "outputId": "1ca9bbc6-0523-4c37-84a7-6cb84216650c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MYCNN(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "    (5): ReLU()\n",
              "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=3136, out_features=128, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.3, inplace=False)\n",
              "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Dropout(p=0.3, inplace=False)\n",
              "    (7): Linear(in_features=64, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for batch_features, batch_labels in test_loader:\n",
        "\n",
        "    outputs = model(batch_features)\n",
        "\n",
        "    _, prediction = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += batch_labels.size(0)\n",
        "    correct += (prediction == batch_labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHH2L1q6WFBn",
        "outputId": "7cfed9f5-940b-4c68-8765-5fcee8a638b5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 89.41666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "\n",
        "    outputs = model(batch_features)\n",
        "\n",
        "    _, prediction = torch.max(outputs.data, 1)\n",
        "\n",
        "    total += batch_labels.size(0)\n",
        "    correct += (prediction == batch_labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48yEFY65Wxlm",
        "outputId": "68c5efe7-a4a2-48b8-fb86-d1c900ba85dd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 99.9375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning"
      ],
      "metadata": {
        "id": "ZLrBmn0TgTi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies as needed:\n",
        "# pip install kagglehub[pandas-datasets]\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# Set the path to the file you'd like to load\n",
        "file_path = \"fashion-mnist_train.csv\"\n",
        "\n",
        "# Load the latest version\n",
        "df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"zalando-research/fashionmnist\",\n",
        "  file_path,\n",
        "  # Provide any additional arguments like\n",
        "  # sql_query or pandas_kwargs. See the\n",
        "  # documenation for more information:\n",
        "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
        ")\n",
        "\n",
        "print(\"First 5 records:\", df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7272755e-00d7-4889-b7dd-0f3f1a009009",
        "id": "Eu8FfxfTjAXj"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-251015765.py:10: DeprecationWarning: Use dataset_load() instead of load_dataset(). load_dataset() will be removed in a future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'fashionmnist' dataset.\n",
            "First 5 records:    label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
            "0      2       0       0       0       0       0       0       0       0   \n",
            "1      9       0       0       0       0       0       0       0       0   \n",
            "2      6       0       0       0       0       0       0       0       5   \n",
            "3      0       0       0       0       1       2       0       0       0   \n",
            "4      3       0       0       0       0       0       0       0       0   \n",
            "\n",
            "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
            "0       0  ...         0         0         0         0         0         0   \n",
            "1       0  ...         0         0         0         0         0         0   \n",
            "2       0  ...         0         0         0        30        43         0   \n",
            "3       0  ...         3         0         0         0         0         1   \n",
            "4       0  ...         0         0         0         0         0         0   \n",
            "\n",
            "   pixel781  pixel782  pixel783  pixel784  \n",
            "0         0         0         0         0  \n",
            "1         0         0         0         0  \n",
            "2         0         0         0         0  \n",
            "3         0         0         0         0  \n",
            "4         0         0         0         0  \n",
            "\n",
            "[5 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlTIfOicjId7",
        "outputId": "405364f6-007d-4588-ccd9-b98bce97e143"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f5593e67990>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPDOkZEujKLO",
        "outputId": "6194b19f-bc06-45a3-d50d-70f189168427"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8dd7821-fcef-4f35-af1e-ef03b7846b19",
        "id": "RB6obdJVjAXl"
      },
      "source": [
        "df = df.head(6000)\n",
        "print(\"First 5 records of the new df:\", df.head())\n",
        "print(\"Number of rows in the new df:\", len(df))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 records of the new df:    label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
            "0      2       0       0       0       0       0       0       0       0   \n",
            "1      9       0       0       0       0       0       0       0       0   \n",
            "2      6       0       0       0       0       0       0       0       5   \n",
            "3      0       0       0       0       1       2       0       0       0   \n",
            "4      3       0       0       0       0       0       0       0       0   \n",
            "\n",
            "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
            "0       0  ...         0         0         0         0         0         0   \n",
            "1       0  ...         0         0         0         0         0         0   \n",
            "2       0  ...         0         0         0        30        43         0   \n",
            "3       0  ...         3         0         0         0         0         1   \n",
            "4       0  ...         0         0         0         0         0         0   \n",
            "\n",
            "   pixel781  pixel782  pixel783  pixel784  \n",
            "0         0         0         0         0  \n",
            "1         0         0         0         0  \n",
            "2         0         0         0         0  \n",
            "3         0         0         0         0  \n",
            "4         0         0         0         0  \n",
            "\n",
            "[5 rows x 785 columns]\n",
            "Number of rows in the new df: 6000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 4x4 grid of images\n",
        "fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
        "fig.suptitle(\"First 16 Images\", fontsize=16)\n",
        "\n",
        "# Plot the first 16 images from the dataset\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    img = df.iloc[i, 1:].values.reshape(28, 28)  # Reshape to 28x28\n",
        "    ax.imshow(img)  # Display in grayscale\n",
        "    ax.axis('off')  # Remove axis for a cleaner look\n",
        "    ax.set_title(f\"Label: {df.iloc[i, 0]}\")  # Show the label\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to fit the title\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k9QpwlEQjfqI",
        "outputId": "2b56cf6d-a0f0-4926-80b2-f54bd1b868f2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df.iloc[:, 1:].values\n",
        "y_train = df.iloc[:, 0].values"
      ],
      "metadata": {
        "id": "cneNkLCljAXn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)"
      ],
      "metadata": {
        "id": "fr3-bO8QjAXo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import transforms\n",
        "\n",
        "custom_transform =  transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "rquRIUnpjcpi"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__( self, features, labels , transform):\n",
        "    self.features = features\n",
        "    self.labels = labels\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    # 2D image : Fashion MNIST 1D to reshape(28,28)\n",
        "    image = self.features[index].reshape(28,28)\n",
        "\n",
        "    # Image must be in PIL(python imaging Library) format : change datatype(np.uint8)\n",
        "    image = image.astype(np.uint8)\n",
        "\n",
        "    # Color image : (1,28,28) => (3,28,28) tensor\n",
        "    image = np.stack([image]*3, axis=-1)\n",
        "\n",
        "    # Tensor converted into PIL image\n",
        "    image = Image.fromarray(image)\n",
        "\n",
        "    #apply transforms\n",
        "    image = self.transform(image)\n",
        "\n",
        "    #return\n",
        "    return image, torch.tensor(self.labels[index],dtype = torch.long)"
      ],
      "metadata": {
        "id": "s0PHm75Ykf9z"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(X_train, y_train,transform = custom_transform)\n",
        "test_dataset = CustomDataset(X_test, y_test, transform = custom_transform)"
      ],
      "metadata": {
        "id": "4DbT0d4Ul92i"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "z5xL_EzemXg_"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch the pretrained model\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "vgg16 = models.vgg16(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uayj6yuhmdcV",
        "outputId": "d844ae06-8bb0-410b-d286-650ce9fee195"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 528M/528M [00:05<00:00, 92.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnPBsqvhmfzP",
        "outputId": "a60d9659-1f2c-44fa-d539-3c35923381d6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in vgg16.features.parameters():\n",
        "  param.requires_grad=False"
      ],
      "metadata": {
        "id": "4hnyyjw_miZQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16.classifier = nn.Sequential(\n",
        "    nn.Linear(25088, 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(1024, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512, 10)\n",
        ")"
      ],
      "metadata": {
        "id": "mlViwLFimkln"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = vgg16.to(device)"
      ],
      "metadata": {
        "id": "fwjIYRl2mphP"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.0001\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "dDuayuGtmsNy"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(vgg16.classifier.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "-9vtkv1emuJM"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  total_epoch_loss = 0\n",
        "\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "\n",
        "    # move data to gpu\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    outputs = vgg16(batch_features)\n",
        "\n",
        "    print(outputs.shape)\n",
        "    print(batch_labels.shape)\n",
        "\n",
        "    # calculate loss\n",
        "    loss = criterion(outputs, batch_labels)\n",
        "\n",
        "    # back pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # update grads\n",
        "    optimizer.step()\n",
        "\n",
        "    total_epoch_loss = total_epoch_loss + loss.item()\n",
        "\n",
        "    break\n",
        "\n",
        "  avg_loss = total_epoch_loss/len(train_loader)\n",
        "  print(f'Epoch: {epoch + 1} , Loss: {avg_loss}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4Og6P3wmt6q",
        "outputId": "b575e49b-274d-4b11-9315-4790cc0cc1e7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 10])\n",
            "torch.Size([32])\n",
            "Epoch: 1 , Loss: 0.015339447657267252\n",
            "torch.Size([32, 10])\n",
            "torch.Size([32])\n",
            "Epoch: 2 , Loss: 0.015096940994262696\n",
            "torch.Size([32, 10])\n",
            "torch.Size([32])\n",
            "Epoch: 3 , Loss: 0.014729544321695964\n",
            "torch.Size([32, 10])\n",
            "torch.Size([32])\n",
            "Epoch: 4 , Loss: 0.014541714986165365\n",
            "torch.Size([32, 10])\n",
            "torch.Size([32])\n",
            "Epoch: 5 , Loss: 0.01403119405110677\n",
            "torch.Size([32, 10])\n",
            "torch.Size([32])\n",
            "Epoch: 6 , Loss: 0.013625288009643554\n",
            "torch.Size([32, 10])\n",
            "torch.Size([32])\n",
            "Epoch: 7 , Loss: 0.013557624816894532\n",
            "torch.Size([32, 10])\n",
            "torch.Size([32])\n",
            "Epoch: 8 , Loss: 0.013167554537455241\n",
            "torch.Size([32, 10])\n",
            "torch.Size([32])\n",
            "Epoch: 9 , Loss: 0.011959298451741537\n",
            "torch.Size([32, 10])\n",
            "torch.Size([32])\n",
            "Epoch: 10 , Loss: 0.012084218660990397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOrKUvxlnAL0",
        "outputId": "6e010bcf-602f-4649-f138-7375b85704e6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation on test data\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for batch_features, batch_labels in test_loader:\n",
        "\n",
        "    # move data to gpu\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    outputs = vgg16(batch_features)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    total = total + batch_labels.shape[0]\n",
        "\n",
        "    correct = correct + (predicted == batch_labels).sum().item()\n",
        "\n",
        "print(correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM4nNmQYnGY-",
        "outputId": "2b338138-3b21-47ac-d8f1-ffbc9550415b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7091666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation on training data\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "\n",
        "    # move data to gpu\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    outputs = vgg16(batch_features)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    total = total + batch_labels.shape[0]\n",
        "\n",
        "    correct = correct + (predicted == batch_labels).sum().item()\n",
        "\n",
        "print(correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9NQuxVXnLXp",
        "outputId": "692d1c50-4976-4c4e-c8d0-cf5331f41f01"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.726875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN"
      ],
      "metadata": {
        "id": "1WZXImLusE44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "2iDV3NGCLNcF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.colab.files as files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "1OFprFAQtwf6",
        "outputId": "1b716288-bb87-4573-fc3f-294568d6e457"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-20dee836-70ca-49e5-b811-df154a79db3a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-20dee836-70ca-49e5-b811-df154a79db3a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 100_Unique_QA_Dataset.csv to 100_Unique_QA_Dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# Assuming the uploaded file name is available in the 'uploaded' dictionary\n",
        "# If you uploaded a different file, replace the key with the correct filename\n",
        "for filename in uploaded.keys():\n",
        "  df = pd.read_csv(io.StringIO(uploaded[filename].decode('utf-8')))\n",
        "  print(f\"DataFrame created from {filename}\")\n",
        "  display(df.head()) # Display the first 5 rows of the dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "nFbwTlMqtMWF",
        "outputId": "096a735c-3371-4250-fb18-fde3f6bd0455"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame created from 100_Unique_QA_Dataset.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                          question      answer\n",
              "0                   What is the capital of France?       Paris\n",
              "1                  What is the capital of Germany?      Berlin\n",
              "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
              "3  What is the largest planet in our solar system?     Jupiter\n",
              "4   What is the boiling point of water in Celsius?         100"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95288536-b23f-4e4f-b258-efbefc13b28b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the capital of France?</td>\n",
              "      <td>Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the capital of Germany?</td>\n",
              "      <td>Berlin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
              "      <td>Harper-Lee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the largest planet in our solar system?</td>\n",
              "      <td>Jupiter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the boiling point of water in Celsius?</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95288536-b23f-4e4f-b258-efbefc13b28b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-95288536-b23f-4e4f-b258-efbefc13b28b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-95288536-b23f-4e4f-b258-efbefc13b28b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1a20ea90-d240-4db6-97b9-80a1cb556ff4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1a20ea90-d240-4db6-97b9-80a1cb556ff4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1a20ea90-d240-4db6-97b9-80a1cb556ff4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"  display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"What is the capital of Germany?\",\n          \"What is the boiling point of water in Celsius?\",\n          \"Who wrote 'To Kill a Mockingbird'?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Berlin\",\n          \"100\",\n          \"Harper-Lee\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize\n",
        "def tokenize(text):\n",
        "  text = text.lower()\n",
        "  text = text.replace('?','')\n",
        "  text = text.replace('!','')\n",
        "  text = text.replace(',','')\n",
        "  text = text.replace('.','')\n",
        "  text = text.replace('(','')\n",
        "  text = text.replace(')','')\n",
        "  return text.split()"
      ],
      "metadata": {
        "id": "i_xnm7dlt4Ju"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize('What is the capital of France?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVX3lBBVuCWI",
        "outputId": "57786e05-8572-4f17-f93e-82f866d2bd10"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'is', 'the', 'capital', 'of', 'france']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Vocab = {'<UNK>':0}"
      ],
      "metadata": {
        "id": "73-XmFB8HhDk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(row):\n",
        "  # print(row['question'],row['answer'])\n",
        "  tokenize_question = tokenize(row['question'])\n",
        "  tokenize_answer = tokenize(row['answer'])\n",
        "  # print(tokenize_question,tokenize_answer)\n",
        "  merged_token = tokenize_question + tokenize_answer\n",
        "  # print(merged_token)\n",
        "  for token in merged_token:\n",
        "    if token not in Vocab:\n",
        "      Vocab[token] = len(Vocab)"
      ],
      "metadata": {
        "id": "CMJQIhwcGbnx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(build_vocab,axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "qq1RPHKJGuUu",
        "outputId": "69eadf71-1e4f-4038-b192-282a57be1f08"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     None\n",
              "1     None\n",
              "2     None\n",
              "3     None\n",
              "4     None\n",
              "      ... \n",
              "85    None\n",
              "86    None\n",
              "87    None\n",
              "88    None\n",
              "89    None\n",
              "Length: 90, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9-KxCuHH4Qk",
        "outputId": "a78d9022-a3de-4361-ca33-9f2f87518bad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<UNK>': 0,\n",
              " 'what': 1,\n",
              " 'is': 2,\n",
              " 'the': 3,\n",
              " 'capital': 4,\n",
              " 'of': 5,\n",
              " 'france': 6,\n",
              " 'paris': 7,\n",
              " 'germany': 8,\n",
              " 'berlin': 9,\n",
              " 'who': 10,\n",
              " 'wrote': 11,\n",
              " \"'to\": 12,\n",
              " 'kill': 13,\n",
              " 'a': 14,\n",
              " \"mockingbird'\": 15,\n",
              " 'harper-lee': 16,\n",
              " 'largest': 17,\n",
              " 'planet': 18,\n",
              " 'in': 19,\n",
              " 'our': 20,\n",
              " 'solar': 21,\n",
              " 'system': 22,\n",
              " 'jupiter': 23,\n",
              " 'boiling': 24,\n",
              " 'point': 25,\n",
              " 'water': 26,\n",
              " 'celsius': 27,\n",
              " '100': 28,\n",
              " 'painted': 29,\n",
              " 'mona': 30,\n",
              " 'lisa': 31,\n",
              " 'leonardo-da-vinci': 32,\n",
              " 'square': 33,\n",
              " 'root': 34,\n",
              " '64': 35,\n",
              " '8': 36,\n",
              " 'chemical': 37,\n",
              " 'symbol': 38,\n",
              " 'for': 39,\n",
              " 'gold': 40,\n",
              " 'au': 41,\n",
              " 'which': 42,\n",
              " 'year': 43,\n",
              " 'did': 44,\n",
              " 'world': 45,\n",
              " 'war': 46,\n",
              " 'ii': 47,\n",
              " 'end': 48,\n",
              " '1945': 49,\n",
              " 'longest': 50,\n",
              " 'river': 51,\n",
              " 'nile': 52,\n",
              " 'japan': 53,\n",
              " 'tokyo': 54,\n",
              " 'developed': 55,\n",
              " 'theory': 56,\n",
              " 'relativity': 57,\n",
              " 'albert-einstein': 58,\n",
              " 'freezing': 59,\n",
              " 'fahrenheit': 60,\n",
              " '32': 61,\n",
              " 'known': 62,\n",
              " 'as': 63,\n",
              " 'red': 64,\n",
              " 'mars': 65,\n",
              " 'author': 66,\n",
              " \"'1984'\": 67,\n",
              " 'george-orwell': 68,\n",
              " 'currency': 69,\n",
              " 'united': 70,\n",
              " 'kingdom': 71,\n",
              " 'pound': 72,\n",
              " 'india': 73,\n",
              " 'delhi': 74,\n",
              " 'discovered': 75,\n",
              " 'gravity': 76,\n",
              " 'newton': 77,\n",
              " 'how': 78,\n",
              " 'many': 79,\n",
              " 'continents': 80,\n",
              " 'are': 81,\n",
              " 'there': 82,\n",
              " 'on': 83,\n",
              " 'earth': 84,\n",
              " '7': 85,\n",
              " 'gas': 86,\n",
              " 'do': 87,\n",
              " 'plants': 88,\n",
              " 'use': 89,\n",
              " 'photosynthesis': 90,\n",
              " 'co2': 91,\n",
              " 'smallest': 92,\n",
              " 'prime': 93,\n",
              " 'number': 94,\n",
              " '2': 95,\n",
              " 'invented': 96,\n",
              " 'telephone': 97,\n",
              " 'alexander-graham-bell': 98,\n",
              " 'australia': 99,\n",
              " 'canberra': 100,\n",
              " 'ocean': 101,\n",
              " 'pacific-ocean': 102,\n",
              " 'speed': 103,\n",
              " 'light': 104,\n",
              " 'vacuum': 105,\n",
              " '299792458m/s': 106,\n",
              " 'language': 107,\n",
              " 'spoken': 108,\n",
              " 'brazil': 109,\n",
              " 'portuguese': 110,\n",
              " 'penicillin': 111,\n",
              " 'alexander-fleming': 112,\n",
              " 'canada': 113,\n",
              " 'ottawa': 114,\n",
              " 'mammal': 115,\n",
              " 'whale': 116,\n",
              " 'element': 117,\n",
              " 'has': 118,\n",
              " 'atomic': 119,\n",
              " '1': 120,\n",
              " 'hydrogen': 121,\n",
              " 'tallest': 122,\n",
              " 'mountain': 123,\n",
              " 'everest': 124,\n",
              " 'city': 125,\n",
              " 'big': 126,\n",
              " 'apple': 127,\n",
              " 'newyork': 128,\n",
              " 'planets': 129,\n",
              " \"'starry\": 130,\n",
              " \"night'\": 131,\n",
              " 'vangogh': 132,\n",
              " 'formula': 133,\n",
              " 'h2o': 134,\n",
              " 'italy': 135,\n",
              " 'rome': 136,\n",
              " 'country': 137,\n",
              " 'famous': 138,\n",
              " 'sushi': 139,\n",
              " 'was': 140,\n",
              " 'first': 141,\n",
              " 'person': 142,\n",
              " 'to': 143,\n",
              " 'step': 144,\n",
              " 'moon': 145,\n",
              " 'armstrong': 146,\n",
              " 'main': 147,\n",
              " 'ingredient': 148,\n",
              " 'guacamole': 149,\n",
              " 'avocado': 150,\n",
              " 'sides': 151,\n",
              " 'does': 152,\n",
              " 'hexagon': 153,\n",
              " 'have': 154,\n",
              " '6': 155,\n",
              " 'china': 156,\n",
              " 'yuan': 157,\n",
              " \"'pride\": 158,\n",
              " 'and': 159,\n",
              " \"prejudice'\": 160,\n",
              " 'jane-austen': 161,\n",
              " 'iron': 162,\n",
              " 'fe': 163,\n",
              " 'hardest': 164,\n",
              " 'natural': 165,\n",
              " 'substance': 166,\n",
              " 'diamond': 167,\n",
              " 'continent': 168,\n",
              " 'by': 169,\n",
              " 'area': 170,\n",
              " 'asia': 171,\n",
              " 'president': 172,\n",
              " 'states': 173,\n",
              " 'george-washington': 174,\n",
              " 'bird': 175,\n",
              " 'its': 176,\n",
              " 'ability': 177,\n",
              " 'mimic': 178,\n",
              " 'sounds': 179,\n",
              " 'parrot': 180,\n",
              " 'longest-running': 181,\n",
              " 'animated': 182,\n",
              " 'tv': 183,\n",
              " 'show': 184,\n",
              " 'simpsons': 185,\n",
              " 'vaticancity': 186,\n",
              " 'most': 187,\n",
              " 'moons': 188,\n",
              " 'saturn': 189,\n",
              " \"'romeo\": 190,\n",
              " \"juliet'\": 191,\n",
              " 'shakespeare': 192,\n",
              " \"earth's\": 193,\n",
              " 'atmosphere': 194,\n",
              " 'nitrogen': 195,\n",
              " 'bones': 196,\n",
              " 'adult': 197,\n",
              " 'human': 198,\n",
              " 'body': 199,\n",
              " '206': 200,\n",
              " 'metal': 201,\n",
              " 'liquid': 202,\n",
              " 'at': 203,\n",
              " 'room': 204,\n",
              " 'temperature': 205,\n",
              " 'mercury': 206,\n",
              " 'russia': 207,\n",
              " 'moscow': 208,\n",
              " 'electricity': 209,\n",
              " 'benjamin-franklin': 210,\n",
              " 'second-largest': 211,\n",
              " 'land': 212,\n",
              " 'color': 213,\n",
              " 'ripe': 214,\n",
              " 'banana': 215,\n",
              " 'yellow': 216,\n",
              " 'month': 217,\n",
              " '28': 218,\n",
              " 'days': 219,\n",
              " 'common': 220,\n",
              " 'february': 221,\n",
              " 'study': 222,\n",
              " 'living': 223,\n",
              " 'organisms': 224,\n",
              " 'called': 225,\n",
              " 'biology': 226,\n",
              " 'home': 227,\n",
              " 'great': 228,\n",
              " 'wall': 229,\n",
              " 'bees': 230,\n",
              " 'collect': 231,\n",
              " 'from': 232,\n",
              " 'flowers': 233,\n",
              " 'nectar': 234,\n",
              " 'opposite': 235,\n",
              " \"'day'\": 236,\n",
              " 'night': 237,\n",
              " 'south': 238,\n",
              " 'korea': 239,\n",
              " 'seoul': 240,\n",
              " 'bulb': 241,\n",
              " 'edison': 242,\n",
              " 'humans': 243,\n",
              " 'breathe': 244,\n",
              " 'survival': 245,\n",
              " 'oxygen': 246,\n",
              " '144': 247,\n",
              " '12': 248,\n",
              " 'pyramids': 249,\n",
              " 'giza': 250,\n",
              " 'egypt': 251,\n",
              " 'sea': 252,\n",
              " 'creature': 253,\n",
              " 'eight': 254,\n",
              " 'arms': 255,\n",
              " 'octopus': 256,\n",
              " 'holiday': 257,\n",
              " 'celebrated': 258,\n",
              " 'december': 259,\n",
              " '25': 260,\n",
              " 'christmas': 261,\n",
              " 'yen': 262,\n",
              " 'legs': 263,\n",
              " 'spider': 264,\n",
              " 'sport': 265,\n",
              " 'uses': 266,\n",
              " 'net': 267,\n",
              " 'ball': 268,\n",
              " 'hoop': 269,\n",
              " 'basketball': 270,\n",
              " 'kangaroos': 271,\n",
              " 'female': 272,\n",
              " 'minister': 273,\n",
              " 'uk': 274,\n",
              " 'margaretthatcher': 275,\n",
              " 'fastest': 276,\n",
              " 'animal': 277,\n",
              " 'cheetah': 278,\n",
              " 'periodic': 279,\n",
              " 'table': 280,\n",
              " 'spain': 281,\n",
              " 'madrid': 282,\n",
              " 'closest': 283,\n",
              " 'sun': 284,\n",
              " 'father': 285,\n",
              " 'computers': 286,\n",
              " 'charlesbabbage': 287,\n",
              " 'mexico': 288,\n",
              " 'mexicocity': 289,\n",
              " 'colors': 290,\n",
              " 'rainbow': 291,\n",
              " 'musical': 292,\n",
              " 'instrument': 293,\n",
              " 'black': 294,\n",
              " 'white': 295,\n",
              " 'keys': 296,\n",
              " 'piano': 297,\n",
              " 'americas': 298,\n",
              " '1492': 299,\n",
              " 'christophercolumbus': 300,\n",
              " 'disney': 301,\n",
              " 'character': 302,\n",
              " 'long': 303,\n",
              " 'nose': 304,\n",
              " 'grows': 305,\n",
              " 'it': 306,\n",
              " 'when': 307,\n",
              " 'lying': 308,\n",
              " 'pinocchio': 309,\n",
              " 'directed': 310,\n",
              " 'movie': 311,\n",
              " \"'titanic'\": 312,\n",
              " 'jamescameron': 313,\n",
              " 'superhero': 314,\n",
              " 'also': 315,\n",
              " 'dark': 316,\n",
              " 'knight': 317,\n",
              " 'batman': 318,\n",
              " 'brasilia': 319,\n",
              " 'fruit': 320,\n",
              " 'king': 321,\n",
              " 'fruits': 322,\n",
              " 'mango': 323,\n",
              " 'eiffel': 324,\n",
              " 'tower': 325}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert words to numerical indices\n",
        "def text_to_indices(text, vocab):\n",
        "\n",
        "  indexed_text = []\n",
        "\n",
        "  for token in tokenize(text):\n",
        "\n",
        "    if token in vocab:\n",
        "      indexed_text.append(vocab[token])\n",
        "    else:\n",
        "      indexed_text.append(vocab['<UNK>'])\n",
        "\n",
        "  return indexed_text"
      ],
      "metadata": {
        "id": "IgwcIqksH6em"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(Vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MebWwpkKMcoC",
        "outputId": "b27d1e8c-4c59-4fc2-add2-10c8e528fead"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_to_indices(\"What is CampushX\",Vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCSCSf_AIr58",
        "outputId": "fea794fe-48ff-47e5-db8c-0d01e90046e5"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class QADataset(Dataset):\n",
        "\n",
        "  def __init__(self, df, vocab):\n",
        "    self.df = df\n",
        "    self.vocab = vocab\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.df.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    numerical_question = text_to_indices(self.df.iloc[index]['question'], self.vocab)\n",
        "    numerical_answer = text_to_indices(self.df.iloc[index]['answer'], self.vocab)\n",
        "\n",
        "    return torch.tensor(numerical_question), torch.tensor(numerical_answer)"
      ],
      "metadata": {
        "id": "duhIbfaSI5Zs"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = QADataset(df, Vocab)"
      ],
      "metadata": {
        "id": "FJwHrMdZLD6L"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pCeWH6YLHKY",
        "outputId": "9436d198-5a29-43da-bb90-5fa682f0b569"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3, 4, 5, 6]), tensor([7]))"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=1 , shuffle=True)"
      ],
      "metadata": {
        "id": "Y9SV87QQLHIM"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "IV34s5QtMLR2"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim=50)\n",
        "    self.rnn = nn.RNN(50, 64, batch_first=True)\n",
        "    self.fc = nn.Linear(64, vocab_size)\n",
        "\n",
        "  def forward(self, question):\n",
        "    embedded_question = self.embedding(question)\n",
        "    hidden, final = self.rnn(embedded_question)\n",
        "    output = self.fc(final.squeeze(0))\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "SnOvucZFMmBv"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = nn.Embedding(326, embedding_dim=50)"
      ],
      "metadata": {
        "id": "cQouqVB8OjSy"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xx = X(dataset[15][0])"
      ],
      "metadata": {
        "id": "CE0zjow6O7ft"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = nn.RNN(50,64)"
      ],
      "metadata": {
        "id": "5dBLd4MtPBhO"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y(xx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJCfyFHCPNG3",
        "outputId": "4d38cf85-c77a-490a-8bf8-53518b38a401"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "FB57WhJpPmv2"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleRNN(len(Vocab))"
      ],
      "metadata": {
        "id": "AjhCRcnOQIiE"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "rer4XPPYPzpG"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  total_loss = 0\n",
        "\n",
        "  for question, answer in dataloader:\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    output = model(question)\n",
        "\n",
        "    # loss -> output shape (1,324) - (1)\n",
        "    loss = criterion(output, answer[0])\n",
        "\n",
        "    # gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # update\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "  print(f\"Epoch: {epoch+1}, Loss: {total_loss:4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AexARIpaQsjt",
        "outputId": "3f9e9f92-ffb2-46a1-cb81-2aa56251c030"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 119.221318\n",
            "Epoch: 2, Loss: 98.582564\n",
            "Epoch: 3, Loss: 79.703439\n",
            "Epoch: 4, Loss: 65.949859\n",
            "Epoch: 5, Loss: 51.996502\n",
            "Epoch: 6, Loss: 39.431384\n",
            "Epoch: 7, Loss: 22.839055\n",
            "Epoch: 8, Loss: 15.947196\n",
            "Epoch: 9, Loss: 13.662065\n",
            "Epoch: 10, Loss: 7.381986\n",
            "Epoch: 11, Loss: 4.183384\n",
            "Epoch: 12, Loss: 3.937460\n",
            "Epoch: 13, Loss: 3.653017\n",
            "Epoch: 14, Loss: 3.515152\n",
            "Epoch: 15, Loss: 3.525442\n",
            "Epoch: 16, Loss: 5.218866\n",
            "Epoch: 17, Loss: 3.941561\n",
            "Epoch: 18, Loss: 3.504399\n",
            "Epoch: 19, Loss: 3.474640\n",
            "Epoch: 20, Loss: 3.168722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, question, threshold=0.5):\n",
        "\n",
        "  # convert question to numbers\n",
        "  numerical_question = text_to_indices(question, Vocab)\n",
        "\n",
        "  # tensor\n",
        "  question_tensor = torch.tensor(numerical_question).unsqueeze(0)\n",
        "\n",
        "  # send to model\n",
        "  output = model(question_tensor)\n",
        "\n",
        "  # convert logits to probs\n",
        "  probs = torch.nn.functional.softmax(output, dim=1)\n",
        "\n",
        "  # find index of max prob\n",
        "  value, index = torch.max(probs, dim=1)\n",
        "\n",
        "  if value < threshold:\n",
        "    print(\"I don't know\")\n",
        "\n",
        "  print(list(Vocab.keys())[index])"
      ],
      "metadata": {
        "id": "r8YD6eiXVXFs"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, \"What is the largest animal in our solar panel?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAMS8OESW0Yc",
        "outputId": "0c3fddb3-7e05-4d35-cf54-64f470c24713"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pacific-ocean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "EGuGUpvZcWHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldU94vS-camP",
        "outputId": "7e843087-910e-4b6f-af83-f400c7fa149d"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk"
      ],
      "metadata": {
        "id": "CVy1u25QcoN8"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = \"\"\"About the Program\n",
        "What is the course fee for  Data Science Mentorship Program (DSMP 2023)\n",
        "The course follows a monthly subscription model where you have to make monthly payments of Rs 799/month.\n",
        "What is the total duration of the course?\n",
        "The total duration of the course is 7 months. So the total course fee becomes 799*7 = Rs 5600(approx.)\n",
        "What is the syllabus of the mentorship program?\n",
        "We will be covering the following modules:\n",
        "Python Fundamentals\n",
        "Python libraries for Data Science\n",
        "Data Analysis\n",
        "SQL for Data Science\n",
        "Maths for Machine Learning\n",
        "ML Algorithms\n",
        "Practical ML\n",
        "MLOPs\n",
        "Case studies\n",
        "You can check the detailed syllabus here - https://learnwith.campusx.in/courses/CampusX-Data-Science-Mentorship-Program-637339afe4b0615a1bbed390\n",
        "Will Deep Learning and NLP be a part of this program?\n",
        "No, NLP and Deep Learning both are not a part of this program’s curriculum.\n",
        "What if I miss a live session? Will I get a recording of the session?\n",
        "Yes all our sessions are recorded, so even if you miss a session you can go back and watch the recording.\n",
        "Where can I find the class schedule?\n",
        "Checkout this google sheet to see month by month time table of the course - https://docs.google.com/spreadsheets/d/16OoTax_A6ORAeCg4emgexhqqPv3noQPYKU7RJ6ArOzk/edit?usp=sharing.\n",
        "What is the time duration of all the live sessions?\n",
        "Roughly, all the sessions last 2 hours.\n",
        "What is the language spoken by the instructor during the sessions?\n",
        "Hinglish\n",
        "How will I be informed about the upcoming class?\n",
        "You will get a mail from our side before every paid session once you become a paid user.\n",
        "Can I do this course if I am from a non-tech background?\n",
        "Yes, absolutely.\n",
        "I am late, can I join the program in the middle?\n",
        "Absolutely, you can join the program anytime.\n",
        "If I join/pay in the middle, will I be able to see all the past lectures?\n",
        "Yes, once you make the payment you will be able to see all the past content in your dashboard.\n",
        "Where do I have to submit the task?\n",
        "You don’t have to submit the task. We will provide you with the solutions, you have to self evaluate the task yourself.\n",
        "Will we do case studies in the program?\n",
        "Yes.\n",
        "Where can we contact you?\n",
        "You can mail us at nitish.campusx@gmail.com\n",
        "Payment/Registration related questions\n",
        "Where do we have to make our payments? Your YouTube channel or website?\n",
        "You have to make all your monthly payments on our website. Here is the link for our website - https://learnwith.campusx.in/\n",
        "Can we pay the entire amount of Rs 5600 all at once?\n",
        "Unfortunately no, the program follows a monthly subscription model.\n",
        "What is the validity of monthly subscription? Suppose if I pay on 15th Jan, then do I have to pay again on 1st Feb or 15th Feb\n",
        "15th Feb. The validity period is 30 days from the day you make the payment. So essentially you can join anytime you don’t have to wait for a month to end.\n",
        "What if I don’t like the course after making the payment. What is the refund policy?\n",
        "You get a 7 days refund period from the day you have made the payment.\n",
        "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
        "You have to contact us by sending a mail at nitish.campusx@gmail.com\n",
        "Post registration queries\n",
        "Till when can I view the paid videos on the website?\n",
        "This one is tricky, so read carefully. You can watch the videos till your subscription is valid. Suppose you have purchased subscription on 21st Jan, you will be able to watch all the past paid sessions in the period of 21st Jan to 20th Feb. But after 21st Feb you will have to purchase the subscription again.\n",
        "But once the course is over and you have paid us Rs 5600(or 7 installments of Rs 799) you will be able to watch the paid sessions till Aug 2024.\n",
        "Why lifetime validity is not provided?\n",
        "Because of the low course fee.\n",
        "Where can I reach out in case of a doubt after the session?\n",
        "You will have to fill a google form provided in your dashboard and our team will contact you for a 1 on 1 doubt clearance session\n",
        "If I join the program late, can I still ask past week doubts?\n",
        "Yes, just select past week doubt in the doubt clearance google form.\n",
        "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
        "You have to contact us by sending a mail at nitish.campusx@gmai.com\n",
        "Certificate and Placement Assistance related queries\n",
        "What is the criteria to get the certificate?\n",
        "There are 2 criterias:\n",
        "You have to pay the entire fee of Rs 5600\n",
        "You have to attempt all the course assessments.\n",
        "I am joining late. How can I pay payment of the earlier months?\n",
        "You will get a link to pay fee of earlier months in your dashboard once you pay for the current month.\n",
        "I have read that Placement assistance is a part of this program. What comes under Placement assistance?\n",
        "This is to clarify that Placement assistance does not mean Placement guarantee. So we dont guarantee you any jobs or for that matter even interview calls. So if you are planning to join this course just for placements, I am afraid you will be disappointed. Here is what comes under placement assistance\n",
        "Portfolio Building sessions\n",
        "Soft skill sessions\n",
        "Sessions with industry mentors\n",
        "Discussion on Job hunting strategies\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "OBTIaDZVcqTr"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72jB1Aj9csRR",
        "outputId": "14d1a980-87cf-40ef-9eb8-ea4e5415e620"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize\n",
        "tokens = word_tokenize(document.lower())"
      ],
      "metadata": {
        "id": "C80A9dm4cuim"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build vocan\n",
        "vocab  = { '<unk>' : 0}\n",
        "\n",
        "for token in tokens:\n",
        "  if token not in vocab:\n",
        "    vocab[token] = len(vocab)\n",
        "\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLs9PwEfc8fu",
        "outputId": "fd8bb958-d6ba-407e-c884-27b5f0f46946"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<unk>': 0,\n",
              " 'about': 1,\n",
              " 'the': 2,\n",
              " 'program': 3,\n",
              " 'what': 4,\n",
              " 'is': 5,\n",
              " 'course': 6,\n",
              " 'fee': 7,\n",
              " 'for': 8,\n",
              " 'data': 9,\n",
              " 'science': 10,\n",
              " 'mentorship': 11,\n",
              " '(': 12,\n",
              " 'dsmp': 13,\n",
              " '2023': 14,\n",
              " ')': 15,\n",
              " 'follows': 16,\n",
              " 'a': 17,\n",
              " 'monthly': 18,\n",
              " 'subscription': 19,\n",
              " 'model': 20,\n",
              " 'where': 21,\n",
              " 'you': 22,\n",
              " 'have': 23,\n",
              " 'to': 24,\n",
              " 'make': 25,\n",
              " 'payments': 26,\n",
              " 'of': 27,\n",
              " 'rs': 28,\n",
              " '799/month': 29,\n",
              " '.': 30,\n",
              " 'total': 31,\n",
              " 'duration': 32,\n",
              " '?': 33,\n",
              " '7': 34,\n",
              " 'months': 35,\n",
              " 'so': 36,\n",
              " 'becomes': 37,\n",
              " '799': 38,\n",
              " '*': 39,\n",
              " '=': 40,\n",
              " '5600': 41,\n",
              " 'approx': 42,\n",
              " 'syllabus': 43,\n",
              " 'we': 44,\n",
              " 'will': 45,\n",
              " 'be': 46,\n",
              " 'covering': 47,\n",
              " 'following': 48,\n",
              " 'modules': 49,\n",
              " ':': 50,\n",
              " 'python': 51,\n",
              " 'fundamentals': 52,\n",
              " 'libraries': 53,\n",
              " 'analysis': 54,\n",
              " 'sql': 55,\n",
              " 'maths': 56,\n",
              " 'machine': 57,\n",
              " 'learning': 58,\n",
              " 'ml': 59,\n",
              " 'algorithms': 60,\n",
              " 'practical': 61,\n",
              " 'mlops': 62,\n",
              " 'case': 63,\n",
              " 'studies': 64,\n",
              " 'can': 65,\n",
              " 'check': 66,\n",
              " 'detailed': 67,\n",
              " 'here': 68,\n",
              " '-': 69,\n",
              " 'https': 70,\n",
              " '//learnwith.campusx.in/courses/campusx-data-science-mentorship-program-637339afe4b0615a1bbed390': 71,\n",
              " 'deep': 72,\n",
              " 'and': 73,\n",
              " 'nlp': 74,\n",
              " 'part': 75,\n",
              " 'this': 76,\n",
              " 'no': 77,\n",
              " ',': 78,\n",
              " 'both': 79,\n",
              " 'are': 80,\n",
              " 'not': 81,\n",
              " '’': 82,\n",
              " 's': 83,\n",
              " 'curriculum': 84,\n",
              " 'if': 85,\n",
              " 'i': 86,\n",
              " 'miss': 87,\n",
              " 'live': 88,\n",
              " 'session': 89,\n",
              " 'get': 90,\n",
              " 'recording': 91,\n",
              " 'yes': 92,\n",
              " 'all': 93,\n",
              " 'our': 94,\n",
              " 'sessions': 95,\n",
              " 'recorded': 96,\n",
              " 'even': 97,\n",
              " 'go': 98,\n",
              " 'back': 99,\n",
              " 'watch': 100,\n",
              " 'find': 101,\n",
              " 'class': 102,\n",
              " 'schedule': 103,\n",
              " 'checkout': 104,\n",
              " 'google': 105,\n",
              " 'sheet': 106,\n",
              " 'see': 107,\n",
              " 'month': 108,\n",
              " 'by': 109,\n",
              " 'time': 110,\n",
              " 'table': 111,\n",
              " '//docs.google.com/spreadsheets/d/16ootax_a6oraecg4emgexhqqpv3noqpyku7rj6arozk/edit': 112,\n",
              " 'usp=sharing': 113,\n",
              " 'roughly': 114,\n",
              " 'last': 115,\n",
              " '2': 116,\n",
              " 'hours': 117,\n",
              " 'language': 118,\n",
              " 'spoken': 119,\n",
              " 'instructor': 120,\n",
              " 'during': 121,\n",
              " 'hinglish': 122,\n",
              " 'how': 123,\n",
              " 'informed': 124,\n",
              " 'upcoming': 125,\n",
              " 'mail': 126,\n",
              " 'from': 127,\n",
              " 'side': 128,\n",
              " 'before': 129,\n",
              " 'every': 130,\n",
              " 'paid': 131,\n",
              " 'once': 132,\n",
              " 'become': 133,\n",
              " 'user': 134,\n",
              " 'do': 135,\n",
              " 'am': 136,\n",
              " 'non-tech': 137,\n",
              " 'background': 138,\n",
              " 'absolutely': 139,\n",
              " 'late': 140,\n",
              " 'join': 141,\n",
              " 'in': 142,\n",
              " 'middle': 143,\n",
              " 'anytime': 144,\n",
              " 'join/pay': 145,\n",
              " 'able': 146,\n",
              " 'past': 147,\n",
              " 'lectures': 148,\n",
              " 'payment': 149,\n",
              " 'content': 150,\n",
              " 'your': 151,\n",
              " 'dashboard': 152,\n",
              " 'submit': 153,\n",
              " 'task': 154,\n",
              " 'don': 155,\n",
              " 't': 156,\n",
              " 'provide': 157,\n",
              " 'with': 158,\n",
              " 'solutions': 159,\n",
              " 'self': 160,\n",
              " 'evaluate': 161,\n",
              " 'yourself': 162,\n",
              " 'contact': 163,\n",
              " 'us': 164,\n",
              " 'at': 165,\n",
              " 'nitish.campusx': 166,\n",
              " '@': 167,\n",
              " 'gmail.com': 168,\n",
              " 'payment/registration': 169,\n",
              " 'related': 170,\n",
              " 'questions': 171,\n",
              " 'youtube': 172,\n",
              " 'channel': 173,\n",
              " 'or': 174,\n",
              " 'website': 175,\n",
              " 'on': 176,\n",
              " 'link': 177,\n",
              " '//learnwith.campusx.in/': 178,\n",
              " 'pay': 179,\n",
              " 'entire': 180,\n",
              " 'amount': 181,\n",
              " 'unfortunately': 182,\n",
              " 'validity': 183,\n",
              " 'suppose': 184,\n",
              " '15th': 185,\n",
              " 'jan': 186,\n",
              " 'then': 187,\n",
              " 'again': 188,\n",
              " '1st': 189,\n",
              " 'feb': 190,\n",
              " 'feb.': 191,\n",
              " 'period': 192,\n",
              " '30': 193,\n",
              " 'days': 194,\n",
              " 'day': 195,\n",
              " 'essentially': 196,\n",
              " 'wait': 197,\n",
              " 'end': 198,\n",
              " 'like': 199,\n",
              " 'after': 200,\n",
              " 'making': 201,\n",
              " 'refund': 202,\n",
              " 'policy': 203,\n",
              " 'made': 204,\n",
              " 'living': 205,\n",
              " 'outside': 206,\n",
              " 'india': 207,\n",
              " 'should': 208,\n",
              " 'sending': 209,\n",
              " 'post': 210,\n",
              " 'registration': 211,\n",
              " 'queries': 212,\n",
              " 'till': 213,\n",
              " 'when': 214,\n",
              " 'view': 215,\n",
              " 'videos': 216,\n",
              " 'one': 217,\n",
              " 'tricky': 218,\n",
              " 'read': 219,\n",
              " 'carefully': 220,\n",
              " 'valid': 221,\n",
              " 'purchased': 222,\n",
              " '21st': 223,\n",
              " '20th': 224,\n",
              " 'but': 225,\n",
              " 'purchase': 226,\n",
              " 'over': 227,\n",
              " 'installments': 228,\n",
              " 'aug': 229,\n",
              " '2024.': 230,\n",
              " 'why': 231,\n",
              " 'lifetime': 232,\n",
              " 'provided': 233,\n",
              " 'because': 234,\n",
              " 'low': 235,\n",
              " 'reach': 236,\n",
              " 'out': 237,\n",
              " 'doubt': 238,\n",
              " 'fill': 239,\n",
              " 'form': 240,\n",
              " 'team': 241,\n",
              " '1': 242,\n",
              " 'clearance': 243,\n",
              " 'still': 244,\n",
              " 'ask': 245,\n",
              " 'week': 246,\n",
              " 'doubts': 247,\n",
              " 'just': 248,\n",
              " 'select': 249,\n",
              " 'gmai.com': 250,\n",
              " 'certificate': 251,\n",
              " 'placement': 252,\n",
              " 'assistance': 253,\n",
              " 'criteria': 254,\n",
              " 'there': 255,\n",
              " 'criterias': 256,\n",
              " 'attempt': 257,\n",
              " 'assessments': 258,\n",
              " 'joining': 259,\n",
              " 'earlier': 260,\n",
              " 'current': 261,\n",
              " 'that': 262,\n",
              " 'comes': 263,\n",
              " 'under': 264,\n",
              " 'clarify': 265,\n",
              " 'does': 266,\n",
              " 'mean': 267,\n",
              " 'guarantee': 268,\n",
              " 'dont': 269,\n",
              " 'any': 270,\n",
              " 'jobs': 271,\n",
              " 'matter': 272,\n",
              " 'interview': 273,\n",
              " 'calls': 274,\n",
              " 'planning': 275,\n",
              " 'placements': 276,\n",
              " 'afraid': 277,\n",
              " 'disappointed': 278,\n",
              " 'portfolio': 279,\n",
              " 'building': 280,\n",
              " 'soft': 281,\n",
              " 'skill': 282,\n",
              " 'industry': 283,\n",
              " 'mentors': 284,\n",
              " 'discussion': 285,\n",
              " 'job': 286,\n",
              " 'hunting': 287,\n",
              " 'strategies': 288}"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLg_uZu8dVbM",
        "outputId": "fc8b956d-e828-492b-a281-0056804eba1f"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "289"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentence = document.split('\\n')"
      ],
      "metadata": {
        "id": "0Zkbg00rdYQb"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_indices(sentence, vocab):\n",
        "\n",
        "  numerical_sentence = []\n",
        "\n",
        "  for token in sentence:\n",
        "    if token in vocab:\n",
        "      numerical_sentence.append(vocab[token])\n",
        "    else:\n",
        "      numerical_sentence.append(vocab['<unk>'])\n",
        "\n",
        "  return numerical_sentence\n"
      ],
      "metadata": {
        "id": "HDysawa9dccX"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_numerical_sentences = []\n",
        "\n",
        "for sentence in input_sentence :\n",
        "  input_numerical_sentences.append(text_to_indices(word_tokenize(sentence.lower()), vocab))\n"
      ],
      "metadata": {
        "id": "CjgR3MQNdiCH"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_numerical_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1A-RNP7dkuD",
        "outputId": "2c4ef5ba-47ab-422b-a2ab-78e2e28757b0"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence = []\n",
        "for sentence in input_numerical_sentences:\n",
        "\n",
        "  for i in range(1, len(sentence)):\n",
        "    training_sequence.append(sentence[:i+1])"
      ],
      "metadata": {
        "id": "obA9YG79eHYJ"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(training_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHWHyuF2eMyu",
        "outputId": "e8ecc015-e41d-44b1-ed5c-5183f34dc9e7"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "942"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_list = []\n",
        "\n",
        "for sequence in training_sequence:\n",
        "  len_list.append(len(sequence))\n",
        "\n",
        "max(len_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXNInKppeQn3",
        "outputId": "4ea1fa91-397e-4e3d-8187-1e50120d9bd6"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vxc1S6rbeVKM",
        "outputId": "4e2b79f1-2ed3-4c16-e627-96f1e4dc62f7"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence = []\n",
        "for sequence in training_sequence:\n",
        "\n",
        "  padded_training_sequence.append([0]*(max(len_list) - len(sequence)) + sequence)"
      ],
      "metadata": {
        "id": "dtPg5uRN9Cc7"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(padded_training_sequence[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqZssF989X-4",
        "outputId": "39f901ba-b91f-4f93-e56e-c074e23ddd7d"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence = torch.tensor(padded_training_sequence, dtype=torch.long)"
      ],
      "metadata": {
        "id": "0_wVpepb9iE4"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogKvdXa79yxV",
        "outputId": "a4fa89ca-86b3-42c6-a0b9-bffb3a53ad9b"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,  ...,   0,   1,   2],\n",
              "        [  0,   0,   0,  ...,   1,   2,   3],\n",
              "        [  0,   0,   0,  ...,   0,   4,   5],\n",
              "        ...,\n",
              "        [  0,   0,   0,  ..., 285, 176, 286],\n",
              "        [  0,   0,   0,  ..., 176, 286, 287],\n",
              "        [  0,   0,   0,  ..., 286, 287, 288]])"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_training_sequence[:, :-1]\n",
        "y = padded_training_sequence[:,-1]"
      ],
      "metadata": {
        "id": "Tz8fwCok90m0"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ed_PLHJ-Dgv",
        "outputId": "7b923068-6906-4a82-9f6d-c714fc044fc9"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,  ...,   0,   0,   1],\n",
              "        [  0,   0,   0,  ...,   0,   1,   2],\n",
              "        [  0,   0,   0,  ...,   0,   0,   4],\n",
              "        ...,\n",
              "        [  0,   0,   0,  ...,   0, 285, 176],\n",
              "        [  0,   0,   0,  ..., 285, 176, 286],\n",
              "        [  0,   0,   0,  ..., 176, 286, 287]])"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eReVrcX9-EUU",
        "outputId": "c836fd76-206e-426a-c52f-1893c2b3c94d"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  2,   3,   5,   2,   6,   7,   8,   9,  10,  11,   3,  12,  13,  14,\n",
              "         15,   6,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  18,  26,\n",
              "         27,  28,  29,  30,   5,   2,  31,  32,  27,   2,   6,  33,  31,  32,\n",
              "         27,   2,   6,   5,  34,  35,  30,  36,   2,  31,   6,   7,  37,  38,\n",
              "         39,  34,  40,  28,  41,  12,  42,  30,  15,   5,   2,  43,  27,   2,\n",
              "         11,   3,  33,  45,  46,  47,   2,  48,  49,  50,  52,  53,   8,   9,\n",
              "         10,  54,   8,   9,  10,   8,  57,  58,  60,  59,  64,  65,  66,   2,\n",
              "         67,  43,  68,  69,  70,  50,  71,  72,  58,  73,  74,  46,  17,  75,\n",
              "         27,  76,   3,  33,  78,  74,  73,  72,  58,  79,  80,  81,  17,  75,\n",
              "         27,  76,   3,  82,  83,  84,  30,  85,  86,  87,  17,  88,  89,  33,\n",
              "         45,  86,  90,  17,  91,  27,   2,  89,  33,  93,  94,  95,  80,  96,\n",
              "         78,  36,  97,  85,  22,  87,  17,  89,  22,  65,  98,  99,  73, 100,\n",
              "          2,  91,  30,  65,  86, 101,   2, 102, 103,  33,  76, 105, 106,  24,\n",
              "        107, 108, 109, 108, 110, 111,  27,   2,   6,  69,  70,  50, 112,  33,\n",
              "        113,  30,   5,   2, 110,  32,  27,  93,   2,  88,  95,  33,  78,  93,\n",
              "          2,  95, 115, 116, 117,  30,   5,   2, 118, 119, 109,   2, 120, 121,\n",
              "          2,  95,  33,  45,  86,  46, 124,   1,   2, 125, 102,  33,  45,  90,\n",
              "         17, 126, 127,  94, 128, 129, 130, 131,  89, 132,  22, 133,  17, 131,\n",
              "        134,  30,  86, 135,  76,   6,  85,  86, 136, 127,  17, 137, 138,  33,\n",
              "         78, 139,  30, 136, 140,  78,  65,  86, 141,   2,   3, 142,   2, 143,\n",
              "         33,  78,  22,  65, 141,   2,   3, 144,  30,  86, 145, 142,   2, 143,\n",
              "         78,  45,  86,  46, 146,  24, 107,  93,   2, 147, 148,  33,  78, 132,\n",
              "         22,  25,   2, 149,  22,  45,  46, 146,  24, 107,  93,   2, 147, 150,\n",
              "        142, 151, 152,  30, 135,  86,  23,  24, 153,   2, 154,  33, 155,  82,\n",
              "        156,  23,  24, 153,   2, 154,  30,  44,  45, 157,  22, 158,   2, 159,\n",
              "         78,  22,  23,  24, 160, 161,   2, 154, 162,  30,  44, 135,  63,  64,\n",
              "        142,   2,   3,  33,  30,  65,  44, 163,  22,  33,  65, 126, 164, 165,\n",
              "        166, 167, 168, 170, 171, 135,  44,  23,  24,  25,  94,  26,  33, 151,\n",
              "        172, 173, 174, 175,  33,  23,  24,  25,  93, 151,  18,  26, 176,  94,\n",
              "        175,  30,  68,   5,   2, 177,   8,  94, 175,  69,  70,  50, 178,  44,\n",
              "        179,   2, 180, 181,  27,  28,  41,  93, 165, 132,  33,  77,  78,   2,\n",
              "          3,  16,  17,  18,  19,  20,  30,   5,   2, 183,  27,  18,  19,  33,\n",
              "        184,  85,  86, 179, 176, 185, 186,  78, 187, 135,  86,  23,  24, 179,\n",
              "        188, 176, 189, 190, 174, 185, 190, 191,   2, 183, 192,   5, 193, 194,\n",
              "        127,   2, 195,  22,  25,   2, 149,  30,  36, 196,  22,  65, 141, 144,\n",
              "         22, 155,  82, 156,  23,  24, 197,   8,  17, 108,  24, 198,  30,  85,\n",
              "         86, 155,  82, 156, 199,   2,   6, 200, 201,   2, 149,  30,   4,   5,\n",
              "          2, 202, 203,  33,  90,  17,  34, 194, 202, 192, 127,   2, 195,  22,\n",
              "         23, 204,   2, 149,  30, 136, 205, 206, 207,  73,  86, 136,  81, 146,\n",
              "         24,  25,   2, 149, 176,   2, 175,  78,   4, 208,  86, 135,  33,  23,\n",
              "         24, 163, 164, 109, 209,  17, 126, 165, 166, 167, 168, 211, 212, 214,\n",
              "         65,  86, 215,   2, 131, 216, 176,   2, 175,  33, 217,   5, 218,  78,\n",
              "         36, 219, 220,  30,  22,  65, 100,   2, 216, 213, 151,  19,   5, 221,\n",
              "         30, 184,  22,  23, 222,  19, 176, 223, 186,  78,  22,  45,  46, 146,\n",
              "         24, 100,  93,   2, 147, 131,  95, 142,   2, 192,  27, 223, 186,  24,\n",
              "        224, 191, 225, 200, 223, 190,  22,  45,  23,  24, 226,   2,  19, 188,\n",
              "         30, 132,   2,   6,   5, 227,  73,  22,  23, 131, 164,  28,  41,  12,\n",
              "        174,  34, 228,  27,  28,  38,  15,  22,  45,  46, 146,  24, 100,   2,\n",
              "        131,  95, 213, 229,   0,  30, 232, 183,   5,  81, 233,  33,  27,   2,\n",
              "        235,   6,   7,  30,  65,  86, 236, 237, 142,  63,  27,  17, 238, 200,\n",
              "          2,  89,  33,  45,  23,  24, 239,  17, 105, 240, 233, 142, 151, 152,\n",
              "         73,  94, 241,  45, 163,  22,   8,  17, 242, 176, 242, 238, 243,  89,\n",
              "         86, 141,   2,   3, 140,  78,  65,  86, 244, 245, 147, 246, 247,  33,\n",
              "         78, 248, 249, 147, 246, 238, 142,   2, 238, 243, 105, 240,  30, 136,\n",
              "        205, 206, 207,  73,  86, 136,  81, 146,  24,  25,   2, 149, 176,   2,\n",
              "        175,  78,   4, 208,  86, 135,  33,  23,  24, 163, 164, 109, 209,  17,\n",
              "        126, 165, 166, 167, 250,  73, 252, 253, 170, 212,   5,   2, 254,  24,\n",
              "         90,   2, 251,  33,  80, 116, 256,  50,  23,  24, 179,   2, 180,   7,\n",
              "         27,  28,  41,  23,  24, 257,  93,   2,   6, 258,  30, 136, 259, 140,\n",
              "         30, 123,  65,  86, 179, 149,  27,   2, 260,  35,  33,  45,  90,  17,\n",
              "        177,  24, 179,   7,  27, 260,  35, 142, 151, 152, 132,  22, 179,   8,\n",
              "          2, 261, 108,  30,  23, 219, 262, 252, 253,   5,  17,  75,  27,  76,\n",
              "          3,  30,   4, 263, 264, 252, 253,  33,   5,  24, 265, 262, 252, 253,\n",
              "        266,  81, 267, 252, 268,  30,  36,  44, 269, 268,  22, 270, 271, 174,\n",
              "          8, 262, 272,  97, 273, 274,  30,  36,  85,  22,  80, 275,  24, 141,\n",
              "         76,   6, 248,   8, 276,  78,  86, 136, 277,  22,  45,  46, 278,  30,\n",
              "         68,   5,   4, 263, 264, 252, 253, 280,  95, 282,  95, 158, 283, 284,\n",
              "        176, 286, 287, 288])"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "fR059hVd-IAf"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(X,y)"
      ],
      "metadata": {
        "id": "KLX0clQM_j9r"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYHaeSuI_nJX",
        "outputId": "5a9581bc-bb16-4081-fb00-53089be6e55e"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "942"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "7ZUeD3l6_oZ3"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, 100)\n",
        "    self.lstm = nn.LSTM(100, 150, batch_first=True)\n",
        "    self.fc = nn.Linear(150, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedded = self.embedding(x)\n",
        "    intermediate_hidden_states, (final_hidden_state, final_cell_state) = self.lstm(embedded)\n",
        "    output = self.fc(final_hidden_state.squeeze(0))\n",
        "    return output"
      ],
      "metadata": {
        "id": "0TEukXmWDEn8"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTMModel(len(vocab))"
      ],
      "metadata": {
        "id": "YcQEVc9aVgr5"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Lvm7W6L1X6P1"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXwq43NRYD3q",
        "outputId": "e6a43cac-5681-4006-eaab-905f3d3c0d97"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): Embedding(289, 100)\n",
              "  (lstm): LSTM(100, 150, batch_first=True)\n",
              "  (fc): Linear(in_features=150, out_features=289, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "1faORN1VYFdu"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "\n",
        "  for batch_x, batch_y in dataloader:\n",
        "\n",
        "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(batch_x)\n",
        "\n",
        "    loss = criterion(output, batch_y)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "  print(f\"Epoch: {epoch + 1}, Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRLc1cbrYVVV",
        "outputId": "ec618ff5-6033-43f4-8de3-2bb44caca75a"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 166.4256\n",
            "Epoch: 2, Loss: 146.1864\n",
            "Epoch: 3, Loss: 133.2687\n",
            "Epoch: 4, Loss: 120.5586\n",
            "Epoch: 5, Loss: 108.4760\n",
            "Epoch: 6, Loss: 97.1628\n",
            "Epoch: 7, Loss: 86.1549\n",
            "Epoch: 8, Loss: 76.1043\n",
            "Epoch: 9, Loss: 67.4020\n",
            "Epoch: 10, Loss: 58.7604\n",
            "Epoch: 11, Loss: 51.4291\n",
            "Epoch: 12, Loss: 45.2155\n",
            "Epoch: 13, Loss: 39.7762\n",
            "Epoch: 14, Loss: 34.7986\n",
            "Epoch: 15, Loss: 30.5753\n",
            "Epoch: 16, Loss: 26.6074\n",
            "Epoch: 17, Loss: 23.5899\n",
            "Epoch: 18, Loss: 20.5098\n",
            "Epoch: 19, Loss: 18.3511\n",
            "Epoch: 20, Loss: 16.6134\n",
            "Epoch: 21, Loss: 14.8766\n",
            "Epoch: 22, Loss: 13.3545\n",
            "Epoch: 23, Loss: 12.1509\n",
            "Epoch: 24, Loss: 11.1674\n",
            "Epoch: 25, Loss: 10.2355\n",
            "Epoch: 26, Loss: 9.5782\n",
            "Epoch: 27, Loss: 8.9193\n",
            "Epoch: 28, Loss: 8.3473\n",
            "Epoch: 29, Loss: 7.8614\n",
            "Epoch: 30, Loss: 7.5140\n",
            "Epoch: 31, Loss: 7.1957\n",
            "Epoch: 32, Loss: 6.8361\n",
            "Epoch: 33, Loss: 6.5160\n",
            "Epoch: 34, Loss: 6.3488\n",
            "Epoch: 35, Loss: 5.9772\n",
            "Epoch: 36, Loss: 5.8673\n",
            "Epoch: 37, Loss: 5.6374\n",
            "Epoch: 38, Loss: 5.5815\n",
            "Epoch: 39, Loss: 5.6198\n",
            "Epoch: 40, Loss: 5.1216\n",
            "Epoch: 41, Loss: 5.0843\n",
            "Epoch: 42, Loss: 4.9638\n",
            "Epoch: 43, Loss: 4.8005\n",
            "Epoch: 44, Loss: 4.7346\n",
            "Epoch: 45, Loss: 4.6686\n",
            "Epoch: 46, Loss: 4.4700\n",
            "Epoch: 47, Loss: 4.5452\n",
            "Epoch: 48, Loss: 4.5532\n",
            "Epoch: 49, Loss: 4.4404\n",
            "Epoch: 50, Loss: 4.2785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "\n",
        "def prediction(model, vocab, text):\n",
        "\n",
        "  # tokenize\n",
        "  tokenized_text = word_tokenize(text.lower())\n",
        "\n",
        "  # text -> numerical indices\n",
        "  numerical_text = text_to_indices(tokenized_text, vocab)\n",
        "\n",
        "  # padding\n",
        "  padded_text = torch.tensor([0] * (61 - len(numerical_text)) + numerical_text, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "  # send to model\n",
        "  output = model(padded_text)\n",
        "\n",
        "  # predicted index\n",
        "  value, index = torch.max(output, dim=1)\n",
        "\n",
        "  # merge with text\n",
        "  return text + \" \" + list(vocab.keys())[index]\n",
        "\n"
      ],
      "metadata": {
        "id": "O9f6DkX-ZM-r"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(model, vocab, \"The course follows a monthly\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VsRgcJysbGCg",
        "outputId": "ed656dbd-217a-4b9d-a9a6-8be954951312"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The course follows a monthly subscription'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "num_tokens = 10\n",
        "input_text = \"i\"\n",
        "\n",
        "for i in range(num_tokens):\n",
        "  output_text = prediction(model, vocab, input_text)\n",
        "  print(output_text)\n",
        "  input_text = output_text\n",
        "  time.sleep(0.5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_JPACfEbNPo",
        "outputId": "649a17b0-1d89-40de-9273-fb2e85e93800"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i am\n",
            "i am living\n",
            "i am living outside\n",
            "i am living outside india\n",
            "i am living outside india and\n",
            "i am living outside india and i\n",
            "i am living outside india and i am\n",
            "i am living outside india and i am not\n",
            "i am living outside india and i am not able\n",
            "i am living outside india and i am not able to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader1 = DataLoader(dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "JXsV4AnNXNnw"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate accuracy\n",
        "def calculate_accuracy(model, dataloader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # No need to compute gradients\n",
        "        for batch_x, batch_y in dataloader1:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "            # Get model predictions\n",
        "            outputs = model(batch_x)\n",
        "\n",
        "            # Get the predicted word indices\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "\n",
        "            # Compare with actual labels\n",
        "            correct += (predicted == batch_y).sum().item()\n",
        "            total += batch_y.size(0)\n",
        "\n",
        "    accuracy = correct / total * 100\n",
        "    return accuracy\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = calculate_accuracy(model, dataloader, device)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "Py7o0rJJc5pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aff043b5-d8ff-494b-e9e1-fb2bbecb3560"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 95.65%\n"
          ]
        }
      ]
    }
  ]
}